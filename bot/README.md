# ğŸ¤– Google Gemini + LangChain + Streamlit Chat App

Este proyecto es una **aplicaciÃ³n de chat interactiva** que utiliza el modelo **Google Gemini** integrado con **LangChain**, y una interfaz en **Streamlit**.  
Permite conversar con un asistente inteligente que responde usando la API de **Google Generative AI**.

---

## ğŸš€ CaracterÃ­sticas

âœ… Interfaz de chat creada con **Streamlit**  
âœ… IntegraciÃ³n con **Google Gemini (Generative AI)**  
âœ… GestiÃ³n del historial de conversaciÃ³n con **LangChain Messages**  
âœ… ConfiguraciÃ³n dinÃ¡mica de **modelo** y **temperatura**  
âœ… Respuestas **en tiempo real** (streaming de tokens)  
âœ… BotÃ³n para **reiniciar la conversaciÃ³n**

---

## ğŸ“¦ Requisitos previos

Antes de ejecutar el proyecto, asegÃºrate de tener:

- Python **3.10+**
- Una **API Key de Google Generative AI**
- Una cuenta activa en **Google AI Studio** o **Google Cloud**
- Entorno virtual (recomendado)

---

## âš™ï¸ InstalaciÃ³n

1. **Clona el repositorio o copia los archivos**

   ```bash
   git clone https://github.com/tuusuario/gemini-langchain-chat.git
   cd gemini-langchain-chat

python3 -m venv venv
source venv/bin/activate   # En Linux / Mac
venv\Scripts\activate      # En Windows

pip install streamlit python-dotenv langchain langchain-google-genai


GOOGLE_API_KEY=tu_clave_aqui
```
ğŸ“ gemini-langchain-chat
â”‚
â”œâ”€â”€ app.py              # CÃ³digo principal de la aplicaciÃ³n
â”œâ”€â”€ .env                # Clave de API de Google
â”œâ”€â”€ requirements.txt     # (Opcional) dependencias del proyecto
â””â”€â”€ README.md
```
streamlit run app.py
```
chat_model = ChatGoogleGenerativeAI(
    model=model_name,
    temperature=temperature,
    google_api_key=GOOGLE_API_KEY
)

template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that helps people find information."),
    ("human", "{historial}\nrespond to: {mensaje}")
])

cadena = template | chat_model

for chunk in cadena.stream({"mensaje": pregunta, "historial": st.session_state.messages}):
    response_placeholder.markdown(full_response + "â–Œ")

```
| Elemento                       | FunciÃ³n                                              |
| ------------------------------ | ---------------------------------------------------- |
| **Sidebar**                    | Permite elegir modelo (`gemini-2.5-*`) y temperatura |
| **Chat Input**                 | Caja de texto para enviar preguntas                  |
| **BotÃ³n â€œClear Conversationâ€** | Limpia el historial de mensajes                      |
| **Chat Area**                  | Muestra las interacciones con el asistente           |

```
ğŸ§‘â€ğŸ’» Autor

Tu Nombre
ğŸ’¼ Desarrollador Backend / IA
ğŸŒ LinkedIn
 | GitHub```
